{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d464a255-be3b-4f8c-afa7-f3798bd84c01",
   "metadata": {},
   "source": [
    "# Implementing the Single layer perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d58c32a-4010-4180-b904-698c46c10146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3682608a-7733-48d2-8ec5-2b1005a15d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepFuntion(x):\n",
    "    return 1 if x>=0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3689a121-fac5-4f42-bb6d-c73bcec97669",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset\n",
    "x=np.array([\n",
    "    [1, 40],  # Fail\n",
    "    [2, 50],  # Fail\n",
    "    [3, 65],  # Fail\n",
    "    [4, 70],  # Pass\n",
    "    [5, 80],  # Pass\n",
    "    [6, 85],  # Pass\n",
    "    [7, 90]   # Pass\n",
    "])\n",
    "\n",
    "y=np.array([0,0,0,1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1e16ade5-6a20-4572-981f-5b7fdc4a667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the weights ,bias ,learning_rate ,epoch\n",
    "weights=np.random.rand(x.shape[1])\n",
    "bias=np.random.rand()\n",
    "## Assign the weights and bias to the 0\n",
    "# weights=np.zeros(x.shape[1])\n",
    "# bias=0\n",
    "learnig_rate=0.01\n",
    "epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "179f10c1-226b-450d-a1d5-7254e975d6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " For Itteration : 1 , weight = [1.17917128 3.9917038 ] , bias = 0.776715153912739 \n",
      "\n",
      " For Itteration : 2 , weight = [1.27917128 1.9917038 ] , bias = 0.6767151539127391 \n",
      "\n",
      " For Itteration : 3 , weight = [1.57917128 4.9917038 ] , bias = 0.6767151539127391 \n",
      "\n",
      " For Itteration : 4 , weight = [1.67917128 2.9917038 ] , bias = 0.5767151539127391 \n",
      "\n",
      " For Itteration : 5 , weight = [1.97917128 5.9917038 ] , bias = 0.5767151539127391 \n",
      "\n",
      " For Itteration : 6 , weight = [2.07917128 3.9917038 ] , bias = 0.4767151539127391 \n",
      "\n",
      " For Itteration : 7 , weight = [2.17917128 1.9917038 ] , bias = 0.37671515391273913 \n",
      "\n",
      " For Itteration : 8 , weight = [2.47917128 4.9917038 ] , bias = 0.37671515391273913 \n",
      "\n",
      " For Itteration : 9 , weight = [2.57917128 2.9917038 ] , bias = 0.27671515391273915 \n",
      "\n",
      " For Itteration : 10 , weight = [2.87917128 5.9917038 ] , bias = 0.27671515391273915 \n",
      "\n",
      " For Itteration : 11 , weight = [2.97917128 3.9917038 ] , bias = 0.17671515391273915 \n",
      "\n",
      " For Itteration : 12 , weight = [3.07917128 1.9917038 ] , bias = 0.07671515391273914 \n",
      "\n",
      " For Itteration : 13 , weight = [3.37917128 4.9917038 ] , bias = 0.07671515391273914 \n",
      "\n",
      " For Itteration : 14 , weight = [3.47917128 2.9917038 ] , bias = -0.023284846087260863 \n",
      "\n",
      " For Itteration : 15 , weight = [3.77917128 5.9917038 ] , bias = -0.023284846087260863 \n",
      "\n",
      " For Itteration : 16 , weight = [3.87917128 3.9917038 ] , bias = -0.12328484608726087 \n",
      "\n",
      " For Itteration : 17 , weight = [3.97917128 1.9917038 ] , bias = -0.22328484608726087 \n",
      "\n",
      " For Itteration : 18 , weight = [4.27917128 4.9917038 ] , bias = -0.22328484608726087 \n",
      "\n",
      " For Itteration : 19 , weight = [4.37917128 2.9917038 ] , bias = -0.32328484608726094 \n",
      "\n",
      " For Itteration : 20 , weight = [4.67917128 5.9917038 ] , bias = -0.32328484608726094 \n",
      "\n",
      " For Itteration : 21 , weight = [4.77917128 3.9917038 ] , bias = -0.4232848460872609 \n",
      "\n",
      " For Itteration : 22 , weight = [4.87917128 1.9917038 ] , bias = -0.5232848460872609 \n",
      "\n",
      " For Itteration : 23 , weight = [5.17917128 4.9917038 ] , bias = -0.5232848460872609 \n",
      "\n",
      " For Itteration : 24 , weight = [5.27917128 2.9917038 ] , bias = -0.6232848460872609 \n",
      "\n",
      " For Itteration : 25 , weight = [5.57917128 5.9917038 ] , bias = -0.6232848460872609 \n",
      "\n",
      " For Itteration : 26 , weight = [5.67917128 3.9917038 ] , bias = -0.7232848460872608 \n",
      "\n",
      " For Itteration : 27 , weight = [5.77917128 1.9917038 ] , bias = -0.8232848460872608 \n",
      "\n",
      " For Itteration : 28 , weight = [6.07917128 4.9917038 ] , bias = -0.8232848460872608 \n",
      "\n",
      " For Itteration : 29 , weight = [6.17917128 2.9917038 ] , bias = -0.9232848460872608 \n",
      "\n",
      " For Itteration : 30 , weight = [6.47917128 5.9917038 ] , bias = -0.9232848460872608 \n",
      "\n",
      " For Itteration : 31 , weight = [6.57917128 3.9917038 ] , bias = -1.0232848460872608 \n",
      "\n",
      " For Itteration : 32 , weight = [6.67917128 1.9917038 ] , bias = -1.1232848460872609 \n",
      "\n",
      " For Itteration : 33 , weight = [6.97917128 4.9917038 ] , bias = -1.1232848460872609 \n",
      "\n",
      " For Itteration : 34 , weight = [7.07917128 2.9917038 ] , bias = -1.223284846087261 \n",
      "\n",
      " For Itteration : 35 , weight = [7.37917128 5.9917038 ] , bias = -1.223284846087261 \n",
      "\n",
      " For Itteration : 36 , weight = [7.47917128 3.9917038 ] , bias = -1.323284846087261 \n",
      "\n",
      " For Itteration : 37 , weight = [7.57917128 1.9917038 ] , bias = -1.4232848460872611 \n",
      "\n",
      " For Itteration : 38 , weight = [7.87917128 4.9917038 ] , bias = -1.4232848460872611 \n",
      "\n",
      " For Itteration : 39 , weight = [7.97917128 2.9917038 ] , bias = -1.5232848460872612 \n",
      "\n",
      " For Itteration : 40 , weight = [8.27917128 5.9917038 ] , bias = -1.5232848460872612 \n",
      "\n",
      " For Itteration : 41 , weight = [8.37917128 3.9917038 ] , bias = -1.6232848460872613 \n",
      "\n",
      " For Itteration : 42 , weight = [8.47917128 1.9917038 ] , bias = -1.7232848460872614 \n",
      "\n",
      " For Itteration : 43 , weight = [8.77917128 4.9917038 ] , bias = -1.7232848460872614 \n",
      "\n",
      " For Itteration : 44 , weight = [8.87917128 2.9917038 ] , bias = -1.8232848460872615 \n",
      "\n",
      " For Itteration : 45 , weight = [9.17917128 5.9917038 ] , bias = -1.8232848460872615 \n",
      "\n",
      " For Itteration : 46 , weight = [9.27917128 3.9917038 ] , bias = -1.9232848460872614 \n",
      "\n",
      " For Itteration : 47 , weight = [9.37917128 1.9917038 ] , bias = -2.0232848460872614 \n",
      "\n",
      " For Itteration : 48 , weight = [9.67917128 4.9917038 ] , bias = -2.0232848460872614 \n",
      "\n",
      " For Itteration : 49 , weight = [9.77917128 2.9917038 ] , bias = -2.1232848460872615 \n",
      "\n",
      " For Itteration : 50 , weight = [10.07917128  5.9917038 ] , bias = -2.1232848460872615 \n",
      "\n",
      " For Itteration : 51 , weight = [10.17917128  3.9917038 ] , bias = -2.2232848460872616 \n",
      "\n",
      " For Itteration : 52 , weight = [10.27917128  1.9917038 ] , bias = -2.3232848460872617 \n",
      "\n",
      " For Itteration : 53 , weight = [10.57917128  4.9917038 ] , bias = -2.3232848460872617 \n",
      "\n",
      " For Itteration : 54 , weight = [10.67917128  2.9917038 ] , bias = -2.423284846087262 \n",
      "\n",
      " For Itteration : 55 , weight = [10.97917128  5.9917038 ] , bias = -2.423284846087262 \n",
      "\n",
      " For Itteration : 56 , weight = [11.07917128  3.9917038 ] , bias = -2.523284846087262 \n",
      "\n",
      " For Itteration : 57 , weight = [11.17917128  1.9917038 ] , bias = -2.623284846087262 \n",
      "\n",
      " For Itteration : 58 , weight = [11.47917128  4.9917038 ] , bias = -2.623284846087262 \n",
      "\n",
      " For Itteration : 59 , weight = [11.57917128  2.9917038 ] , bias = -2.723284846087262 \n",
      "\n",
      " For Itteration : 60 , weight = [11.87917128  5.9917038 ] , bias = -2.723284846087262 \n",
      "\n",
      " For Itteration : 61 , weight = [11.97917128  3.9917038 ] , bias = -2.823284846087262 \n",
      "\n",
      " For Itteration : 62 , weight = [12.07917128  1.9917038 ] , bias = -2.9232848460872622 \n",
      "\n",
      " For Itteration : 63 , weight = [12.37917128  4.9917038 ] , bias = -2.9232848460872622 \n",
      "\n",
      " For Itteration : 64 , weight = [12.47917128  2.9917038 ] , bias = -3.0232848460872623 \n",
      "\n",
      " For Itteration : 65 , weight = [12.77917128  5.9917038 ] , bias = -3.0232848460872623 \n",
      "\n",
      " For Itteration : 66 , weight = [12.87917128  3.9917038 ] , bias = -3.1232848460872624 \n",
      "\n",
      " For Itteration : 67 , weight = [12.97917128  1.9917038 ] , bias = -3.2232848460872625 \n",
      "\n",
      " For Itteration : 68 , weight = [13.27917128  4.9917038 ] , bias = -3.2232848460872625 \n",
      "\n",
      " For Itteration : 69 , weight = [13.37917128  2.9917038 ] , bias = -3.3232848460872626 \n",
      "\n",
      " For Itteration : 70 , weight = [13.67917128  5.9917038 ] , bias = -3.3232848460872626 \n",
      "\n",
      " For Itteration : 71 , weight = [13.77917128  3.9917038 ] , bias = -3.4232848460872627 \n",
      "\n",
      " For Itteration : 72 , weight = [13.87917128  1.9917038 ] , bias = -3.523284846087263 \n",
      "\n",
      " For Itteration : 73 , weight = [14.17917128  4.9917038 ] , bias = -3.523284846087263 \n",
      "\n",
      " For Itteration : 74 , weight = [14.27917128  2.9917038 ] , bias = -3.623284846087263 \n",
      "\n",
      " For Itteration : 75 , weight = [14.57917128  5.9917038 ] , bias = -3.623284846087263 \n",
      "\n",
      " For Itteration : 76 , weight = [14.67917128  3.9917038 ] , bias = -3.723284846087263 \n",
      "\n",
      " For Itteration : 77 , weight = [14.77917128  1.9917038 ] , bias = -3.823284846087263 \n",
      "\n",
      " For Itteration : 78 , weight = [15.07917128  4.9917038 ] , bias = -3.823284846087263 \n",
      "\n",
      " For Itteration : 79 , weight = [15.17917128  2.9917038 ] , bias = -3.9232848460872627 \n",
      "\n",
      " For Itteration : 80 , weight = [15.47917128  5.9917038 ] , bias = -3.9232848460872627 \n",
      "\n",
      " For Itteration : 81 , weight = [15.57917128  3.9917038 ] , bias = -4.023284846087263 \n",
      "\n",
      " For Itteration : 82 , weight = [15.67917128  1.9917038 ] , bias = -4.123284846087262 \n",
      "\n",
      " For Itteration : 83 , weight = [15.97917128  4.9917038 ] , bias = -4.123284846087262 \n",
      "\n",
      " For Itteration : 84 , weight = [16.07917128  2.9917038 ] , bias = -4.223284846087262 \n",
      "\n",
      " For Itteration : 85 , weight = [16.37917128  5.9917038 ] , bias = -4.223284846087262 \n",
      "\n",
      " For Itteration : 86 , weight = [16.47917128  3.9917038 ] , bias = -4.323284846087262 \n",
      "\n",
      " For Itteration : 87 , weight = [16.57917128  1.9917038 ] , bias = -4.423284846087261 \n",
      "\n",
      " For Itteration : 88 , weight = [16.87917128  4.9917038 ] , bias = -4.423284846087261 \n",
      "\n",
      " For Itteration : 89 , weight = [16.97917128  2.9917038 ] , bias = -4.523284846087261 \n",
      "\n",
      " For Itteration : 90 , weight = [17.27917128  5.9917038 ] , bias = -4.523284846087261 \n",
      "\n",
      " For Itteration : 91 , weight = [17.37917128  3.9917038 ] , bias = -4.623284846087261 \n",
      "\n",
      " For Itteration : 92 , weight = [17.47917128  1.9917038 ] , bias = -4.72328484608726 \n",
      "\n",
      " For Itteration : 93 , weight = [17.77917128  4.9917038 ] , bias = -4.72328484608726 \n",
      "\n",
      " For Itteration : 94 , weight = [17.87917128  2.9917038 ] , bias = -4.82328484608726 \n",
      "\n",
      " For Itteration : 95 , weight = [18.17917128  5.9917038 ] , bias = -4.82328484608726 \n",
      "\n",
      " For Itteration : 96 , weight = [18.27917128  3.9917038 ] , bias = -4.92328484608726 \n",
      "\n",
      " For Itteration : 97 , weight = [18.37917128  1.9917038 ] , bias = -5.023284846087259 \n",
      "\n",
      " For Itteration : 98 , weight = [18.67917128  4.9917038 ] , bias = -5.023284846087259 \n",
      "\n",
      " For Itteration : 99 , weight = [18.77917128  2.9917038 ] , bias = -5.123284846087259 \n",
      "\n",
      " For Itteration : 100 , weight = [19.07917128  5.9917038 ] , bias = -5.123284846087259 \n",
      "\n",
      " For Itteration : 101 , weight = [19.17917128  3.9917038 ] , bias = -5.2232848460872585 \n",
      "\n",
      " For Itteration : 102 , weight = [19.27917128  1.9917038 ] , bias = -5.323284846087258 \n",
      "\n",
      " For Itteration : 103 , weight = [19.57917128  4.9917038 ] , bias = -5.323284846087258 \n",
      "\n",
      " For Itteration : 104 , weight = [19.67917128  2.9917038 ] , bias = -5.423284846087258 \n",
      "\n",
      " For Itteration : 105 , weight = [19.57917128 -1.0082962 ] , bias = -5.5232848460872574 \n",
      "\n",
      " For Itteration : 106 , weight = [19.57917128 -1.0082962 ] , bias = -5.5232848460872574 \n",
      "\n",
      " Training Completed early at itteration 106 So no more updates are needed \n"
     ]
    }
   ],
   "source": [
    "# now The Percerptron Leaning (Udpdating the Weights and bias )\n",
    "for each in range (epochs):\n",
    "    no_update=True\n",
    "    for i in range  (len(x)):\n",
    "        weighted_sum=np.dot(x[i] , weights)+bias\n",
    "        y_pred=stepFuntion(weighted_sum)\n",
    "\n",
    "        error=y[i]-y_pred\n",
    "\n",
    "        if y[i]!=y_pred:\n",
    "            weights=weights+learning_rate*error*x[i]\n",
    "            bias=bias+learning_rate*error\n",
    "            no_update=False\n",
    "    print(f\"\\n For Itteration : {each+1} , weight = {weights} , bias = {bias} \")\n",
    "\n",
    "    \n",
    "    if no_update:\n",
    "        print(f\"\\n Training Completed early at itteration {each+1} So no more updates are needed \")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "de17ebf5-27ad-454b-8c07-baeb8bd9e64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Input : [ 1 40] , Prediction = 0\n",
      "\n",
      " Input : [ 2 50] , Prediction = 0\n",
      "\n",
      " Input : [ 3 65] , Prediction = 0\n",
      "\n",
      " Input : [ 4 70] , Prediction = 1\n",
      "\n",
      " Input : [ 5 80] , Prediction = 1\n",
      "\n",
      " Input : [ 6 85] , Prediction = 1\n",
      "\n",
      " Input : [ 7 90] , Prediction = 1\n"
     ]
    }
   ],
   "source": [
    "# now Time For the Prediction \n",
    "\n",
    "for i in range (len(x)):\n",
    "    weighted_sum=np.dot(x[i],weights)\n",
    "    prediction=stepFuntion(weighted_sum)\n",
    "    print(f\"\\n Input : {x[i]} , Prediction = {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aca9a82-9f56-4f72-86fc-e606d5c6dd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
