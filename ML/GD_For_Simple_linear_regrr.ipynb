{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9e64828-7f08-4703-a363-c9d70af16de1",
   "metadata": {},
   "source": [
    "# Implementing the Gradient Descent For the Simple Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e61b81f-fb8b-4527-8738-e743785752b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4397c701-6ff5-49f8-b6b0-37e49c587a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Enter => How many data points Are There :  5\n",
      "\n",
      " Enter => The Input Data :  1\n",
      "\n",
      " Enter => The Actual Output for the 1.0 input :  2\n",
      "\n",
      " Enter => The Input Data :  2\n",
      "\n",
      " Enter => The Actual Output for the 2.0 input :  4\n",
      "\n",
      " Enter => The Input Data :  3\n",
      "\n",
      " Enter => The Actual Output for the 3.0 input :  6\n",
      "\n",
      " Enter => The Input Data :  4\n",
      "\n",
      " Enter => The Actual Output for the 4.0 input :  8\n",
      "\n",
      " Enter => The Input Data :  5\n",
      "\n",
      " Enter => The Actual Output for the 5.0 input :  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ===== >>>> The Outputs : \n",
      "\n",
      "\n",
      " The Inputs :  [1. 2. 3. 4. 5.]\n",
      "\n",
      " The Outputs :  [ 2.  4.  6.  8. 10.]\n",
      "\n",
      " itteration : 0 , m : 0.4400  , b = 0.1200 , Loss = 44.000000 \n",
      "\n",
      " itteration : 100 , m : 1.8988  , b = 0.3655 , Loss = 0.024474 \n",
      "\n",
      " itteration : 200 , m : 1.9279  , b = 0.2605 , Loss = 0.012432 \n",
      "\n",
      " itteration : 300 , m : 1.9486  , b = 0.1856 , Loss = 0.006315 \n",
      "\n",
      " itteration : 400 , m : 1.9634  , b = 0.1323 , Loss = 0.003208 \n",
      "\n",
      " itteration : 500 , m : 1.9739  , b = 0.0943 , Loss = 0.001630 \n",
      "\n",
      " itteration : 600 , m : 1.9814  , b = 0.0672 , Loss = 0.000828 \n",
      "\n",
      " itteration : 700 , m : 1.9867  , b = 0.0479 , Loss = 0.000420 \n",
      "\n",
      " itteration : 800 , m : 1.9905  , b = 0.0341 , Loss = 0.000214 \n",
      "\n",
      " itteration : 900 , m : 1.9933  , b = 0.0243 , Loss = 0.000108 \n",
      "\n",
      "\n",
      " --------- Final Parametres-------------- \n",
      "\n",
      "\n",
      " The Slope(m) :  1.9951803506719779\n",
      "\n",
      " The Intercept(b) :  0.017400463340610635\n"
     ]
    }
   ],
   "source": [
    "n = int(input(\"\\n Enter => How many data points Are There : \"))\n",
    "x=[]\n",
    "y=[]\n",
    "\n",
    "for i in range (0,n):\n",
    "    ip=float(input(\"\\n Enter => The Input Data : \"))\n",
    "    we=float(input(f\"\\n Enter => The Actual Output for the {ip} input : \"))\n",
    "\n",
    "    x.append(ip)\n",
    "    y.append(we)\n",
    "\n",
    "x_arr=np.array(x)\n",
    "y_arr=np.array(y)\n",
    "\n",
    "print(\"\\n\\n ===== >>>> The Outputs : \\n\")\n",
    "print(\"\\n The Inputs : \",x_arr)\n",
    "print(\"\\n The Outputs : \",y_arr)\n",
    "\n",
    "m=0\n",
    "b=0\n",
    "itterations=1000\n",
    "lear_rate=0.01\n",
    "\n",
    "for i in range (0,itterations):\n",
    "\n",
    "    y_pred=m*x_arr+b\n",
    "\n",
    "    mse=np.mean( (y_arr-y_pred)**2 )\n",
    "\n",
    "    # computing the gradients \n",
    "    dm=(-2/n)*sum(x_arr*(y_arr-y_pred))\n",
    "    db=(-2/n)*sum((y_arr-y_pred))\n",
    "\n",
    "    # updating the m and b \n",
    "    m=m-lear_rate*dm\n",
    "    b=b-lear_rate*db\n",
    "\n",
    "    # printing after every 100 itteration \n",
    "\n",
    "    if i%100==0:\n",
    "        print(f\"\\n itteration : {i} , m : {m:.4f}  , b = {b:.4f} , Loss = {mse:>4f} \")\n",
    "\n",
    "\n",
    "print(\"\\n\\n --------- Final Parametres-------------- \\n\")\n",
    "print(\"\\n The Slope(m) : \",m)\n",
    "print(\"\\n The Intercept(b) : \",b)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1c09e4-fdcb-487c-a0bc-4fbf6571c695",
   "metadata": {},
   "source": [
    "# The Above Code with the Matplot Lib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5e11771-237b-4619-8e82-8b5c90aa4de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680551ca-6887-4b59-8223-fb9dcc7466a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(input(\"\\n Enter => How many data points Are There : \"))\n",
    "x=[]\n",
    "y=[]\n",
    "\n",
    "for i in range (0,n):\n",
    "    ip=float(input(\"\\n Enter => The Input Data : \"))\n",
    "    we=float(input(f\"\\n Enter => The Actual Output for the {ip} input : \"))\n",
    "\n",
    "    x.append(ip)\n",
    "    y.append(we)\n",
    "\n",
    "x_arr=np.array(x)\n",
    "y_arr=np.array(y)\n",
    "\n",
    "print(\"\\n\\n ===== >>>> The Outputs : \\n\")\n",
    "print(\"\\n The Inputs : \",x_arr)\n",
    "print(\"\\n The Outputs : \",y_arr)\n",
    "\n",
    "m=0\n",
    "b=0\n",
    "itterations=1000\n",
    "lear_rate=0.01\n",
    "loss_history=[]\n",
    "\n",
    "for i in range (0,itterations):\n",
    "\n",
    "    y_pred=m*x_arr+b\n",
    "\n",
    "    mse=np.mean( (y_arr-y_pred)**2 )\n",
    "    loss_history.append(mse)\n",
    "    \n",
    "    # computing the gradients \n",
    "    dm=(-2/n)*sum(x_arr*(y_arr-y_pred))\n",
    "    db=(-2/n)*sum((y_arr-y_pred))\n",
    "\n",
    "    # updating the m and b \n",
    "    m=m-lear_rate*dm\n",
    "    b=b-lear_rate*db\n",
    "\n",
    "    # printing after every 100 itteration \n",
    "\n",
    "    if i%100==0:\n",
    "        print(f\"\\n itteration : {i} , m : {m:.4f}  , b = {b:.4f} , Loss = {mse:>4f} \")\n",
    "\n",
    "\n",
    "print(\"\\n\\n --------- Final Parametres-------------- \\n\")\n",
    "print(\"\\n The Slope(m) : \",m)\n",
    "print(\"\\n The Intercept(b) : \",b)\n",
    "\n",
    "\n",
    "    \n",
    "# Plot MSE over iterations\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(itterations), loss_history, label='MSE Loss', color='b')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.title('Gradient Descent for Simple Linear regression ')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05303f36-57a9-4771-bf74-c985cb56d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
